{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zlP2TPgNbqyO",
        "outputId": "a3b6a5f8-0618-4519-d620-10c0c866a6d0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unzipping complete!\n"
          ]
        }
      ],
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "# Path to your zip file in Google Drive\n",
        "zip_path = '/content/drive/MyDrive/brain_tumor_dataset1.zip'\n",
        "\n",
        "# Destination folder to extract\n",
        "extract_path = '/content/dataset'\n",
        "\n",
        "# Unzip\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_path)\n",
        "\n",
        "print(\"Unzipping complete!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from glob import glob\n",
        "# STEP 1: Imports\n",
        "import os\n",
        "import numpy as np\n",
        "import shap\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from tensorflow.keras.models import load_model, Model\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "import zipfile\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import numpy as np\n",
        "from sklearn.cluster import KMeans\n",
        "import matplotlib.pyplot as plt\n",
        "import os"
      ],
      "metadata": {
        "id": "X2ezq0DtQ-_O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "def segment_and_save_masks_cpu(image_path, output_dir, num_segments=10):\n",
        "    # Get image name without extension\n",
        "    img_name = os.path.splitext(os.path.basename(image_path))[0]\n",
        "\n",
        "    # Load image in grayscale\n",
        "    img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
        "    if img is None:\n",
        "        print(f\"Warning: Could not read {image_path}\")\n",
        "        return\n",
        "\n",
        "    h, w = img.shape\n",
        "    flat_img = img.reshape((-1, 1)).astype(np.float32)\n",
        "\n",
        "    # Perform KMeans clustering\n",
        "    kmeans = KMeans(n_clusters=num_segments, random_state=42, n_init='auto')\n",
        "    labels = kmeans.fit_predict(flat_img)\n",
        "\n",
        "    # Create and save masks\n",
        "    for i in range(num_segments):\n",
        "        mask = (labels == i).astype(np.uint8).reshape((h, w)) * 255\n",
        "        mask_filename = f\"{img_name}_segment_{i+1}.png\"\n",
        "        mask_path = os.path.join(output_dir, mask_filename)\n",
        "        cv2.imwrite(mask_path, mask)\n",
        "\n",
        "def batch_segment_directory_cpu(input_dir, output_dir='segmentation_masks', num_segments=10):\n",
        "    # Create output directory if not exists\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    # Collect all image files\n",
        "    image_paths = glob.glob(os.path.join(input_dir, \"*.png\")) + \\\n",
        "                  glob.glob(os.path.join(input_dir, \"*.jpg\")) + \\\n",
        "                  glob.glob(os.path.join(input_dir, \"*.jpeg\"))\n",
        "\n",
        "    total = len(image_paths)\n",
        "    print(f\"Found {total} images. Starting segmentation...\")\n",
        "\n",
        "    # Process each image\n",
        "    for idx, image_path in enumerate(image_paths, 1):\n",
        "        print(f\"[{idx}/{total}] Processing: {os.path.basename(image_path)}\")\n",
        "        segment_and_save_masks_cpu(image_path, output_dir, num_segments=num_segments)\n",
        "\n",
        "    print(\"✅ All images processed and masks saved to:\", output_dir)\n",
        "\n",
        "# Example usage:\n",
        "batch_segment_directory_cpu('/content/dataset/brain_tumor_dataset1', output_dir='all_masks_output', num_segments=10)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jZXsBn7rduBa",
        "outputId": "7a2f4001-b2f5-43a4-fcef-1035eadfad4c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 179 images. Starting segmentation...\n",
            "[1/179] Processing: no 9.png\n",
            "[2/179] Processing: Y92.png\n",
            "[3/179] Processing: Y14.jpg\n",
            "[4/179] Processing: 33 no.jpg\n",
            "[5/179] Processing: 46 no.jpg\n",
            "[6/179] Processing: 6 no.jpg\n",
            "[7/179] Processing: Y154.jpg\n",
            "[8/179] Processing: No16.jpg\n",
            "[9/179] Processing: 12 no.jpg\n",
            "[10/179] Processing: Y186.jpg\n",
            "[11/179] Processing: Y153.jpg\n",
            "[12/179] Processing: Y79.jpg\n",
            "[13/179] Processing: 11 no.jpg\n",
            "[14/179] Processing: 36 no.jpg\n",
            "[15/179] Processing: Y78.jpg\n",
            "[16/179] Processing: No13.jpg\n",
            "[17/179] Processing: Y95.jpg\n",
            "[18/179] Processing: Y70.jpg\n",
            "[19/179] Processing: 3 no.jpg\n",
            "[20/179] Processing: no 94.jpg\n",
            "[21/179] Processing: Y46.jpg\n",
            "[22/179] Processing: Y77.jpg\n",
            "[23/179] Processing: 34 no.jpg\n",
            "[24/179] Processing: Y245.jpg\n",
            "[25/179] Processing: Y168.jpg\n",
            "[26/179] Processing: no 1.jpg\n",
            "[27/179] Processing: Y81.jpg\n",
            "[28/179] Processing: 28 no.jpg\n",
            "[29/179] Processing: no 6.jpg\n",
            "[30/179] Processing: Y82.jpg\n",
            "[31/179] Processing: Y28.jpg\n",
            "[32/179] Processing: Y188.jpg\n",
            "[33/179] Processing: No19.jpg\n",
            "[34/179] Processing: No18.jpg\n",
            "[35/179] Processing: 14 no.jpg\n",
            "[36/179] Processing: Y55.jpg\n",
            "[37/179] Processing: Y54.jpg\n",
            "[38/179] Processing: 18 no.jpg\n",
            "[39/179] Processing: Y62.jpg\n",
            "[40/179] Processing: Y27.jpg\n",
            "[41/179] Processing: no 10.jpg\n",
            "[42/179] Processing: Y73.jpg\n",
            "[43/179] Processing: 7 no.jpg\n",
            "[44/179] Processing: 29 no.jpg\n",
            "[45/179] Processing: Y4.jpg\n",
            "[46/179] Processing: Y8.jpg\n",
            "[47/179] Processing: 38 no.jpg\n",
            "[48/179] Processing: 42 no.jpg\n",
            "[49/179] Processing: Y185.jpg\n",
            "[50/179] Processing: no 8.jpg\n",
            "[51/179] Processing: Y21.jpg\n",
            "[52/179] Processing: 17 no.jpg\n",
            "[53/179] Processing: Y15.jpg\n",
            "[54/179] Processing: 41 no.jpg\n",
            "[55/179] Processing: Y41.jpg\n",
            "[56/179] Processing: 37 no.jpg\n",
            "[57/179] Processing: Y91.jpg\n",
            "[58/179] Processing: No14.jpg\n",
            "[59/179] Processing: Y24.jpg\n",
            "[60/179] Processing: Y252.jpg\n",
            "[61/179] Processing: Y56.jpg\n",
            "[62/179] Processing: No22.jpg\n",
            "[63/179] Processing: No11.jpg\n",
            "[64/179] Processing: N17.jpg\n",
            "[65/179] Processing: no 95.jpg\n",
            "[66/179] Processing: N21.jpg\n",
            "[67/179] Processing: 32 no.jpg\n",
            "[68/179] Processing: Y169.jpg\n",
            "[69/179] Processing: 26 no.jpg\n",
            "[70/179] Processing: Y3.jpg\n",
            "[71/179] Processing: Y250.jpg\n",
            "[72/179] Processing: Y2.jpg\n",
            "[73/179] Processing: Y105.jpg\n",
            "[74/179] Processing: N15.jpg\n",
            "[75/179] Processing: Y102.jpg\n",
            "[76/179] Processing: no 99.jpg\n",
            "[77/179] Processing: Y7.jpg\n",
            "[78/179] Processing: Y52.jpg\n",
            "[79/179] Processing: 47 no.jpg\n",
            "[80/179] Processing: Y53.jpg\n",
            "[81/179] Processing: Y33.jpg\n",
            "[82/179] Processing: Y6.jpg\n",
            "[83/179] Processing: Y92.jpg\n",
            "[84/179] Processing: 22 no.jpg\n",
            "[85/179] Processing: no 923.jpg\n",
            "[86/179] Processing: 13 no.jpg\n",
            "[87/179] Processing: no.jpg\n",
            "[88/179] Processing: Y26.jpg\n",
            "[89/179] Processing: 27 no.jpg\n",
            "[90/179] Processing: No17.jpg\n",
            "[91/179] Processing: N3.jpg\n",
            "[92/179] Processing: Y106.jpg\n",
            "[93/179] Processing: 43 no.jpg\n",
            "[94/179] Processing: no 100.jpg\n",
            "[95/179] Processing: Y76.jpg\n",
            "[96/179] Processing: Y194.jpg\n",
            "[97/179] Processing: no 3.jpg\n",
            "[98/179] Processing: Y22.jpg\n",
            "[99/179] Processing: 4 no.jpg\n",
            "[100/179] Processing: no 97.jpg\n",
            "[101/179] Processing: N11.jpg\n",
            "[102/179] Processing: No20.jpg\n",
            "[103/179] Processing: Y38.jpg\n",
            "[104/179] Processing: 44no.jpg\n",
            "[105/179] Processing: 10 no.jpg\n",
            "[106/179] Processing: Y10.jpg\n",
            "[107/179] Processing: Y29.jpg\n",
            "[108/179] Processing: Y257.jpg\n",
            "[109/179] Processing: 40 no.jpg\n",
            "[110/179] Processing: Y96.jpg\n",
            "[111/179] Processing: Y30.jpg\n",
            "[112/179] Processing: no 2.jpg\n",
            "[113/179] Processing: Y90.jpg\n",
            "[114/179] Processing: Y31.jpg\n",
            "[115/179] Processing: 31 no.jpg\n",
            "[116/179] Processing: Y42.jpg\n",
            "[117/179] Processing: 49 no.jpg\n",
            "[118/179] Processing: Y12.jpg\n",
            "[119/179] Processing: Y35.jpg\n",
            "[120/179] Processing: Y107.jpg\n",
            "[121/179] Processing: 21 no.jpg\n",
            "[122/179] Processing: Y34.jpg\n",
            "[123/179] Processing: Y13.jpg\n",
            "[124/179] Processing: Y9.jpg\n",
            "[125/179] Processing: Y183.jpg\n",
            "[126/179] Processing: Y108.jpg\n",
            "[127/179] Processing: Y162.jpg\n",
            "[128/179] Processing: Y103.jpg\n",
            "[129/179] Processing: no 89.jpg\n",
            "[130/179] Processing: 19 no.jpg\n",
            "[131/179] Processing: Y25.jpg\n",
            "[132/179] Processing: N5.jpg\n",
            "[133/179] Processing: N16.jpg\n",
            "[134/179] Processing: Y60.jpg\n",
            "[135/179] Processing: 45 no.jpg\n",
            "[136/179] Processing: Y180.jpg\n",
            "[137/179] Processing: 8 no.jpg\n",
            "[138/179] Processing: 9 no.jpg\n",
            "[139/179] Processing: Y1.jpg\n",
            "[140/179] Processing: no 90.jpg\n",
            "[141/179] Processing: Y187.jpg\n",
            "[142/179] Processing: 23 no.jpg\n",
            "[143/179] Processing: 20 no.jpg\n",
            "[144/179] Processing: No21.jpg\n",
            "[145/179] Processing: N6.jpg\n",
            "[146/179] Processing: no 4.jpg\n",
            "[147/179] Processing: no 98.jpg\n",
            "[148/179] Processing: 39 no.jpg\n",
            "[149/179] Processing: 15 no.jpg\n",
            "[150/179] Processing: 5 no.jpg\n",
            "[151/179] Processing: Y39.jpg\n",
            "[152/179] Processing: 25 no.jpg\n",
            "[153/179] Processing: Y61.jpg\n",
            "[154/179] Processing: Y32.jpg\n",
            "[155/179] Processing: 35 no.jpg\n",
            "[156/179] Processing: Y74.jpg\n",
            "[157/179] Processing: No12.jpg\n",
            "[158/179] Processing: 24 no.jpg\n",
            "[159/179] Processing: Y37.jpg\n",
            "[160/179] Processing: No15.jpg\n",
            "[161/179] Processing: no 96.jpg\n",
            "[162/179] Processing: Y254.jpg\n",
            "[163/179] Processing: no 92.jpg\n",
            "[164/179] Processing: Y104.jpg\n",
            "[165/179] Processing: 30 no.jpg\n",
            "[166/179] Processing: Y101.jpg\n",
            "[167/179] Processing: Y181.jpg\n",
            "[168/179] Processing: Y69.jpg\n",
            "[169/179] Processing: Y11.jpg\n",
            "[170/179] Processing: Y51.jpg\n",
            "[171/179] Processing: Y17.jpg\n",
            "[172/179] Processing: Y20.jpg\n",
            "[173/179] Processing: 50 no.jpg\n",
            "[174/179] Processing: no 5.jpeg\n",
            "[175/179] Processing: 2 no.jpeg\n",
            "[176/179] Processing: no 91.jpeg\n",
            "[177/179] Processing: 1 no.jpeg\n",
            "[178/179] Processing: no 7.jpeg\n",
            "[179/179] Processing: 48 no.jpeg\n",
            "✅ All images processed and masks saved to: all_masks_output\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "\n",
        "def zip_output_folder(folder_path, zip_name='segmentation_masks.zip'):\n",
        "    shutil.make_archive(base_name=zip_name.replace('.zip', ''), format='zip', root_dir=folder_path)\n",
        "    print(f\"✅ Zipped folder created: {zip_name}\")\n",
        "\n",
        "# Example usage:\n",
        "zip_output_folder('/content/all_masks_output')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dJE5d4ichBx7",
        "outputId": "7d258205-982c-4e13-fc8e-a545e61cd9da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Zipped folder created: segmentation_masks.zip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define paths\n",
        "concepts_base_path = \"/content/dataset1234/kmeans/concept\"\n",
        "background_path = \"/content/dataset1234/kmeans/random\"\n",
        "model_path = \"/content/drive/MyDrive/new_mri.keras\"\n",
        "intermediate_layer_name = \"bottleneck\"  # Change if need"
      ],
      "metadata": {
        "id": "C1UJva8shxRE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load model and create bottleneck model\n",
        "model = load_model(model_path)\n",
        "bottleneck_output = model.get_layer(intermediate_layer_name).output\n",
        "bottleneck_model = Model(inputs=model.input, outputs=bottleneck_output)"
      ],
      "metadata": {
        "id": "gs9-XNq0RcCT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Helper function to load images\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "import numpy as np\n",
        "\n",
        "def load_images_from_folder(folder_path, target_size=(224, 224), color_mode='grayscale', max_images=None):\n",
        "    images = []\n",
        "    filenames = os.listdir(folder_path)\n",
        "    for i, file in enumerate(filenames):\n",
        "        if max_images and i >= max_images:\n",
        "            break\n",
        "        img_path = os.path.join(folder_path, file)\n",
        "        img = load_img(img_path, target_size=target_size, color_mode=color_mode)\n",
        "        img = img_to_array(img)\n",
        "        images.append(img)\n",
        "    return np.array(images)"
      ],
      "metadata": {
        "id": "V260g41VRikZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loop through all concept folders\n",
        "concept_scores = {}\n",
        "for concept_name in os.listdir(concepts_base_path):\n",
        "    concept_folder = os.path.join(concepts_base_path, concept_name)\n",
        "    if not os.path.isdir(concept_folder):\n",
        "        continue\n",
        "    concept_images = load_images_from_folder(concept_folder)\n",
        "    concept_features = bottleneck_model.predict(concept_images)\n",
        "\n",
        "    # Compute ConceptSHAP score (cosine similarity)\n",
        "    similarities = cosine_similarity(concept_features, background_features)\n",
        "\n",
        "    mean_score = np.mean(similarities)\n",
        "    concept_scores[concept_name] = mean_score\n",
        "    print(f\"✅ ConceptSHAP score for '{concept_name}': {mean_score:.4f}\")\n"
      ],
      "metadata": {
        "id": "n92A-l5nRljS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.bar(concept_scores.keys(), concept_scores.values(), color='skyblue')\n",
        "plt.title(\"ConceptSHAP Scores\")\n",
        "plt.xlabel(\"Concept\")\n",
        "plt.ylabel(\"Score\")\n",
        "plt.xticks(rotation=45)\n",
        "plt.grid(axis='y')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "8TZAm2FDSCdt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}